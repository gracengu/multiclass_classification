{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a59fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T21:41:16.709984Z",
     "start_time": "2021-08-24T21:41:04.204117Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, logging \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, Markdown, HTML, clear_output, display_html\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "from src.config import Config\n",
    "from src.analysis import Analysis\n",
    "from src.train import Train\n",
    "\n",
    "analysis = Analysis()\n",
    "train = Train()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e2b7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T23:05:20.360966Z",
     "start_time": "2021-08-24T23:05:19.889006Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2> Data Science Technical Assessment </h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032c97b471ed4d3a959b075be2610b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Accordion(children=(Output(),), _titles={'0': 'Input Data'}), Accordion(children=(Output(), Outpâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Widget Accordians\n",
    "display(Markdown(\"<h2> Data Science Technical Assessment </h2>\"))\n",
    "loading_section = [\"Input Data\"]\n",
    "sections = [\"Introduction\", \"Basic Data Analysis\", \"Missing Data and Outlier Analysis\", \"Feature Engineering and Selection\", \"Model Results and Summary\", \"Conclusion\"]\n",
    "sub_section_1 = [\"Introduction\", \"Assumptions\"]\n",
    "sub_section_2 = [\"Output/Target Analysis\", \"Summary Statistics\", \"Distribution Analysis\"]\n",
    "sub_section_3 = [\"Missing Data Analysis\", \"Outlier Analysis\"]\n",
    "sub_section_4 = [\"Data Transformation\", \"PCA Transformation\", \"Feature Selection\"]\n",
    "sub_section_5 = [\"Machine Learning Model Results\", \"Deep Learning Results\"]\n",
    "sub_section_6 = [\"Model Selection\", \"Future Recommendation\"]\n",
    "\n",
    "accordions = OrderedDict()\n",
    "accordions[\"** Loading **\"] = widgets.Accordion(children=[widgets.Output() for section in loading_section])\n",
    "[accordions[\"** Loading **\"].set_title(i, section) for i, section in enumerate(loading_section)]\n",
    "\n",
    "for section in sections:\n",
    "    if section == \"Introduction\":\n",
    "        task = sub_section_1\n",
    "    elif section == \"Basic Data Analysis\":\n",
    "        task = sub_section_2\n",
    "    elif section == \"Missing Data and Outlier Analysis\":\n",
    "        task = sub_section_3\n",
    "    elif section == \"Feature Engineering and Selection\":\n",
    "        task = sub_section_4\n",
    "    elif section == \"Model Results and Analysis\":\n",
    "        task = sub_section_5\n",
    "    elif section == \"Conclusion\":\n",
    "        task = sub_section_6\n",
    "        \n",
    "    accordions[section] = widgets.Accordion(children=[widgets.Output() for sub_section in task])\n",
    "    [accordions[section].set_title(i, sub_section) for i, sub_section in enumerate(task)]\n",
    "        \n",
    "    \n",
    "widget_fields = widgets.Tab(children=[accordions[t] for t in accordions])\n",
    "[widget_fields.set_title(i, sub) for i, sub in enumerate(accordions.keys())]\n",
    "widget_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80123f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T23:17:18.248899Z",
     "start_time": "2021-08-24T23:17:16.160884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading accordion\n",
    "%matplotlib agg\n",
    "section_0 = \"Introduction\"\n",
    "\n",
    "with accordions[\"** Loading **\"].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown(\"<h3> Initiating data loading ... </h3>\"))\n",
    "    data = analysis.read_file()\n",
    "    \n",
    "with accordions[section_0].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown('''<h3> Problem Statement: </h3>'''))\n",
    "    display(Markdown('''This html file documents the pre-analytics, analytics and model summary for the technical assessment\n",
    "    provided. The problem is a classification/ anomaly detection problem with 150 input variables and a largely imbalanced \\\n",
    "    target class. This report is written in html/ markdown format which can be embedded into a cloud platform. Standard practice \\\n",
    "    is to create a markdown report as a user's/data scientist's handbook on data science analysis and machine learning \\\n",
    "    model selection. With just an additional 1-2 days of work, an API can also be embedded in the report to allow users to use the predictive model \\\n",
    "    as an API. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Blueprint Setup Before Starting: </h3>'''))\n",
    "    display(Markdown('''A blueprint is prepared before starting the task - this simulates s typical agile sprint planning.\n",
    "    The blueprint for the use case is setup as follows: \n",
    "    <ol>\n",
    "        <li> Data import and Pre-EDA </li>\n",
    "        <li> Data cleaning/ Missing data imputation </li>\n",
    "        <li> EDA: Outlier analysis </li>\n",
    "        <li> EDA: Statistical/Distribution analysis </li>\n",
    "        <li> EDA: Feature Engineering and Selection </li>\n",
    "        <li> Modelling - Machine Learning: Simple Tree Based Classifier/ kNN Classifier </li>\n",
    "        <li> Modelling - Deep Learning: Neural Net </li>\n",
    "        <li> Cross Validation (Overfitting/Underfitting)  </li>\n",
    "        <li> Model Evaluation: Selection of Metrics </li>\n",
    "    </ol>''')) \\\n",
    "    \n",
    "    display(Markdown('''To start, the following first steps are prioritized, the results are then iteratively improved: \n",
    "    <ol>\n",
    "        <li> Data import and Pre-EDA </li>\n",
    "        <li> Data cleaning: Delete rows with missing values </li>\n",
    "        <li> EDA: Feature Selection using ANOVA </li>\n",
    "        <li> Modelling - Machine Learning: Random Forest Classifier </li>\n",
    "        <li> Cross Validation and Hyperparameter Tuning  </li>\n",
    "        <li> Model Evaluation: Selection of Metrics </li>\n",
    "    </ol>'''))\n",
    "    \n",
    "    display(Markdown('''Some research questions to start with: \n",
    "    <ol>\n",
    "        <li> Are there class imbalances in the target variable? </li>\n",
    "        <li> How does the input variables vary for the multiclass target?  </li>\n",
    "        <li> Are the input variables normally distributed? </li>\n",
    "        <li> Is there any outlier in the input variables, are these outliers specific to one of the class in the target? </li>\n",
    "        <li> Are the multiclass target represent different failure modes/ defects in the manufacturing/semicon industry?  </li>\n",
    "    </ol>'''))\n",
    "    \n",
    "    \n",
    "    display(Markdown('''<h3> Scope of Work: </h3>\n",
    "    <ol>\n",
    "        <li> Basic Data Analysis: Target Analysis, Summary Statistics, Distribution Analysis </li>\n",
    "        <li> Missing Data and Outlier Analysis </li>\n",
    "        <li> Feature Engineering and Selection: Data Transformation (Log, Sqrt), PCA Transformation, Feature Selection (ANOVA, Chi2) </li>\n",
    "        <li> Model Results and Summary: Machine Learning and Deep Learning </li>\n",
    "        <li> Conclusion: Model Selection and Future Recommendation  </li>\n",
    "    </ol>'''))\n",
    "    \n",
    "    \n",
    "with accordions[section_0].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown('''The assumptions, constants and thresholds are written in the config file. The config file allows \\\n",
    "    quick onboarding/ maintainability of the analysis and model. This helps data scientists to move between teams easily \\\n",
    "    and fast. '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Main Assumptions: </h3>\n",
    "    <ol>\n",
    "        <li> The majority class is assumed to be normal operating mode, while minorities are assumed to be failures/defects. </li>\n",
    "        <li> Faily symmetrical distributions are assumed to be normally distributed. </li>\n",
    "        <li> The critical value for ANOVA and Chi2 Feature Selection is set as 0.05. </li>\n",
    "    </ol>'''))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b800c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T23:19:15.886397Z",
     "start_time": "2021-08-24T23:17:27.704425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading accordion\n",
    "%matplotlib agg\n",
    "section_1 = \"Basic Data Analysis\"\n",
    "    \n",
    "with accordions[section_1].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown('''The target variable is a categorical variable, inherently, this is a classification use case. \\\n",
    "    Class imbalances is a common problem in classification use cases and will result with poor model performances. \\\n",
    "    The poor model performances is attributed to low representation of the minority class in the training data. \\\n",
    "    Here we evaluate the class imbalances in the target variable to decide way forward. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Bar plot for Target Variable </h3>'''))\n",
    "    display(analysis.categorical_barplot(data, \"target\", \"Target Classes\", \"Frequency of target variables\"))\n",
    "    \n",
    "    display(Markdown('''The target variable has significant class imbalances. There are a total of 5 labels where 0\\\n",
    "    is the majority class. '''))\n",
    "    \n",
    "    display(Markdown('''Initial Hypothesis: This seems to be an anomaly detection problem where 0 is assumed to be \\\n",
    "    normal operating mode while the rest is assumed to be different types of defects/failure modes/abnormal event.'''))\n",
    "    \n",
    "    display(Markdown('''Research Questions: Knowing that the data is heavily imbalance, the following are some of the \\\n",
    "    initial questions/suspicions: \\\n",
    "    \n",
    "    <ol>\n",
    "        <li>How is the behaviour of the minority class as compared to the majority class in the input variables?  </li>\n",
    "        <li>Is there any outlier in the input variables, are these outliers specific to one of the class in the target? </li>\n",
    "        <li>Are the multiclass target represent different failure modes/ defects in the manufacturing industry? If so control charts might be useful for EDA.</li>\n",
    "    </ol>\n",
    "    '''))\n",
    "      \n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li>Try undersampling/oversampling techniques for training data i.e oversampling on minority class vs. undersampling on majority class.  </li>\n",
    "        <li>Using control charts, can we identify the \"anomalies\" / minority class assuming our hypothesis is correct.  </li>\n",
    "    </ol>\n",
    "    \n",
    "    '''))\n",
    "    \n",
    "    \n",
    "with accordions[section_1].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown('''<h3> Summary Statistics for Numerical and Categorical variables </h3>'''))\n",
    "    summary_numerical = analysis.summary_statistics(data, \"numerical\")\n",
    "    summary_categorical = analysis.summary_statistics(data, \"categorical\")\n",
    "    \n",
    "    display(analysis.categorical_barplot(summary_numerical, \"kurtosis type\", \"Kurtosis type\", \"Variable count for kurtosis types\"))\n",
    "    display(analysis.categorical_barplot(summary_numerical, \"skewness type\", \"Skewness type\", \"Variable count for skewness types\"))\n",
    "    display(analysis.categorical_barplot(summary_numerical, \"skewness lvl\", \"Skewness lvl\", \"Variable count for skewness lvl\"))\n",
    "        \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> There are no mesokurtic variables. There are more platykurtic (thin tailed) variables than leptokurtic (heavy tailed) variables.</li>\n",
    "        <li> None of the variables are normally distributed. There are more positively skewed than negatively skewed. </li>\n",
    "        <li> Despite none are normally distributed, we use the following threshold to prioritize variables that are moderately or highly skewed: </li>\\\n",
    "        <ul>\n",
    "             <li> if -0.5 < skewness < 0.5: faily symmetrical </li>\n",
    "             <li> if -1.0 < skewness < -0.5 or 0.5 < skewness < 1.0: moderately skewed </li>\n",
    "             <li> if -1.0 < skewness < 1.0: highly skewed </li>\n",
    "        </ul>\n",
    "    </ol>\n",
    "    '''))\n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Evaluate leptokurtic variables: remove outliers whenever possible. Especially the ones with normal class i.e. '0'. </li>\n",
    "        <li> Perform data transformation for moderately and highly skewed. </li>\n",
    "        <li> Perform statistical analysis to double check if variables follow normal distribution. </li>\n",
    "    </ol>\n",
    "\n",
    "    '''))\n",
    "    \n",
    "    \n",
    "with accordions[section_1].children[2]:\n",
    "    clear_output()\n",
    "    display(Markdown('''<h3> Histogram plots </h3>'''))\n",
    "    display(Markdown('''The following plots are an extension from the analysis from \"Summary Statistics\"'''))\n",
    "    analysis.histogram_plot(data, type=\"before\")\n",
    "        \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> There are 2-3 variables (Variable 145, 147 and 105) that looks like a bimodal distribution. </li>\n",
    "        <li> The fairly symmmetrical distributions can be assumed to be normally distributed. We can skip data transformation for these variables for now.  </li>\n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> For the bimodal distributions, maybe worth taking time to understand the behavior of the different \\\n",
    "        localities of the distribution for these variables, but i'll skip this for now. Though, we can't do data \n",
    "        transformations for these variables. </li>\n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Box Plot Analysis </h3>'''))\n",
    "    display(Markdown('''A standard scaling is performed to view plots on the same scale.'''))\n",
    "    X = analysis.data_scaling(data)\n",
    "    start_col, end_col= 10, 20\n",
    "    for col in X.columns:\n",
    "        if end_col <= len(X.columns)+2:\n",
    "            fig, start_col, end_col = analysis.boxplot(X, col, start_col, end_col)\n",
    "            display(fig)\n",
    "            \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> The variance in variables are very small. Higher variance is preferred to avoid overfitting the model to a small range of data. It depends on domain knowledge also, if the variance is inherently small, there's nothing to do about it. </li>\n",
    "        <li> There are a lot of outliers, but a further analysis on outlier needs to be done, which we are going to use x-charts for. </li>\n",
    "    </ol>\n",
    "    '''))\n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Perform outlier analysis using x-charts/ control charts. </li>\n",
    "    </ol>\n",
    "\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cd34f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T23:19:34.291679Z",
     "start_time": "2021-08-24T23:19:15.906579Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "section_2 = \"Missing Data and Outlier Analysis\"\n",
    "    \n",
    "with accordions[section_2].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown('''In missing data analysis, usually columns with more than 70% missingness will be removed; while \\\n",
    "    rows with less than 10% missingness will be removed. We will need to identify if it's missing at random (MAR), missing \\\n",
    "    completely at random (MCAR) or missing not at random (MNAR). \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Missing data pattern for all classes: </h3>'''))\n",
    "    display(analysis.missingness_analysis(data, \"matrix\"))\n",
    "    \n",
    "    display(Markdown('''Observations: Very little proprotion of missingness is seen in the matrix. \\\n",
    "    The missigness have no pattern i.e. missing completely at random (MCAR). In this case, it seems safe to remove \\\n",
    "    the rows. However, care should be taken to avoid removing any minority class. Let's see if there is any missingness for minority class. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: Evaluate missingness count in minority class.'''))\n",
    "    \n",
    "    display(Markdown('''<h3> Missing data count by Target Class: </h3>'''))\n",
    "    missing_data = pd.DataFrame(data.isna().sum()[data.isna().sum() != 0], columns=[\"missing_count\"])\n",
    "    display(analysis.missingness_class(data))\n",
    "\n",
    "    display(Markdown('''Observations: There are only 2 missingness count for minorities in columns 80 and 111 (one each). Removing\n",
    "    the rows will not affect the results too much. In fact, we're performing sampling techniques later to combat the class \\\n",
    "    imbalances. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: Remove missing rows from data.'''))\n",
    "    \n",
    "    \n",
    "with accordions[section_2].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown('''Here comes the exciting part of the analysis. Referring to the earlier \\\n",
    "    research questions written, looking forward to get some answers on the behavior of the minority class from here. \n",
    "    The plan is to use control charts with 3 sigma (standard deviation) control limits i.e. upper control limit (UCL) \\\n",
    "    and lower control limit (LCL) to see if the minority class falls out of these limits. \\\n",
    "    In fact, 3 sigma is the same approach as boxplot techniques, i prefer to see it from the x-chart. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> X-chart for 5 randomly selected columns: </h3>'''))\n",
    "    display(Markdown('''There is a total of 150 columns, here only 5 columns are randomly selected to demonstrate the x-charts. \n",
    "    '''))\n",
    "    selected_cols = [\"0\", \"9\", \"12\", \"19\", \"21\",\"target\"]\n",
    "    temp_data = data.loc[:,data.columns.isin(selected_cols)]\n",
    "    for col in selected_cols:\n",
    "        if col != \"target\":\n",
    "            display(analysis.control_chart(temp_data, col))\n",
    "            \n",
    "            \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> The minority classes are located at the very end of the data, most likely attributed to how the data was prepared. For this, will use random stratified sampling for train test split in model development stage later. </li> \n",
    "        <li> There are x-charts that shows the minority classes belong outside of the UCL and LCL limits, which supports the hypothesis that the minority are anomalies in the dataset.</li> \n",
    "        <li> There are outliers in the majority class that have the same behaviour as the minority class which might confuse the model.  </li> \n",
    "    </ol>\n",
    "   \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Use random stratified sampling for train test split in model development stage later</li> \n",
    "        <li> Plot x-charts for minority classes and identify variables that have data points from minority classes whose behaviour is clearly different from others. </li> \n",
    "        <li> Remove outliers for majority class based on UCL and LCL.  </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> X-chart for Class 2: </h3>'''))\n",
    "    display(Markdown('''The majority class i.e. '0' is removed from the data for the following plots: '''))\n",
    "    selected_cols = [\"9\", \"47\", \"56\", \"73\", \"133\", \"98\", \"100\", \"108\", \"target\"]\n",
    "    temp_data = data.loc[:,data.columns.isin(selected_cols)]\n",
    "    for col in selected_cols:\n",
    "        if col != \"target\":\n",
    "            display(analysis.control_chart(temp_data, col, filter=10000))\n",
    "            \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> Class 2 is beautifully separated from the other minority class. </li> \n",
    "        <li> Note that the normal class might confuse the model and result with False Negatives for Class 2 or False Positives for Class 0.  </li> \n",
    "    </ol>\n",
    "   \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Feature engineering: create flags for variables for when the data point exceed the UCL and LCL limits to help the model identify Class 2. </li> \n",
    "        <li> Outlier removal: remove outliers from majority class when the data point exceed the UCL and LCL limits. </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "            \n",
    "    display(Markdown('''<h3> X-chart for Class 3: </h3>'''))\n",
    "    display(Markdown('''The majority class i.e. '0' is removed from the data for the following plots:'''))\n",
    "    selected_cols = [\"85\", \"117\", \"125\",\"target\"]\n",
    "    temp_data = data.loc[:,data.columns.isin(selected_cols)]\n",
    "    for col in selected_cols:\n",
    "        if col != \"target\":\n",
    "            display(analysis.control_chart(temp_data, col, filter=10000))\n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> Class 3 has behaviours similar to other classes i.e. Class 1 and 4. If the hypothesis that Class 3 is an anomaly is true, then Class 3 is considered a \"weak anomaly\". Suspect poor model performance for this class. </li> \n",
    "        <li> The plots shown are the variables where some class 3 data points exceed the UCL and LCL.  </li>\n",
    "        <li> This is not shown here but by manually going through the plots, Class 1 exhibit similar behaviour as Class 3.  </li> \n",
    "    </ol>\n",
    "   \n",
    "    '''))\n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Same as Class 2, with an additional step: </li> \n",
    "        <li> Principle Component Analysis: perhaps identifying latent variables/ switching the dimension of the variables can identify the hyperplane separating Class 3/ Class 1 from the rest. </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "            \n",
    "    display(Markdown('''<h3> X-chart for Class 4: </h3>'''))\n",
    "    display(Markdown('''The majority class i.e. '0' is removed from the data for the following plots:'''))\n",
    "    selected_cols = [ \"64\", \"128\", \"target\"]\n",
    "    temp_data = data.loc[:,data.columns.isin(selected_cols)]\n",
    "    for col in selected_cols:\n",
    "        if col != \"target\":\n",
    "            display(analysis.control_chart(temp_data, col, filter=10000))\n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> The separation between Class 4 and the rest is not as good as Class 2 but better than Class 3 and 1.   </li> \n",
    "    </ol>\n",
    "   \n",
    "    '''))\n",
    "    display(Markdown('''Next Course of Action: Similar to Class 2'''))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb3b343c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T23:21:36.369810Z",
     "start_time": "2021-08-24T23:19:34.295684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ./data/pca_dataset1.csv ...\n",
      "Data import complete for file: ./data/pca_dataset1.csv ...\n",
      "Reading file: ./data/pca_dataset2.csv ...\n",
      "Data import complete for file: ./data/pca_dataset2.csv ...\n",
      "Reading file: ./data/pca_dataset3.csv ...\n",
      "Data import complete for file: ./data/pca_dataset3.csv ...\n",
      "Reading file: ./data/pca_dataset4.csv ...\n",
      "Data import complete for file: ./data/pca_dataset4.csv ...\n",
      "Reading file: ./data/combined_dataset1.csv ...\n",
      "Data import complete for file: ./data/combined_dataset1.csv ...\n",
      "Reading file: ./data/combined_dataset4.csv ...\n",
      "Data import complete for file: ./data/combined_dataset4.csv ...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "section_4 = \"Feature Engineering and Selection\"\n",
    "pca_df1 = analysis.read_file(\"./data/pca_dataset1.csv\")\n",
    "pca_df2 = analysis.read_file(\"./data/pca_dataset2.csv\")\n",
    "pca_df3 = analysis.read_file(\"./data/pca_dataset3.csv\")\n",
    "pca_df4 = analysis.read_file(\"./data/pca_dataset4.csv\")\n",
    "pca_list = [pca_df1, pca_df2, pca_df3, pca_df4]\n",
    "combined_df1 = analysis.read_file(\"./data/combined_dataset1.csv\")\n",
    "combined_df4 = analysis.read_file(\"./data/combined_dataset4.csv\")\n",
    "\n",
    "with accordions[section_4].children[0]:\n",
    "    clear_output()\n",
    "    display(Markdown('''Based on analysis performed in \"Basic Data Analysis - Summary Statistics\",  this section will perform the necessary \\\n",
    "    transformation steps to ensure that the distribution is fairly symmetrical.   \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> Data Transformation: </h3>'''))\n",
    "    \n",
    "    display(Markdown('''<h4> Variable count by skewness level after data transformation: </h4>'''))\n",
    "    _, transform_df = analysis.data_transformation(data)\n",
    "    display(analysis.categorical_barplot(transform_df, \"skewness lvl\", \"Skewness lvl\", \"Variable count by skewness lvl (after data transformation)\"))\n",
    "    \n",
    "    display(Markdown('''<h4> Histogram plots after data transformation: </h4>'''))\n",
    "    analysis.histogram_plot(data, type=\"after\")\n",
    "    display(Markdown('''Observations: Most were successfully transformed. '''))\n",
    "    display(Markdown('''Next Course of Action: '''))\n",
    "    \n",
    "with accordions[section_4].children[1]:\n",
    "    clear_output()\n",
    "    display(Markdown('''From our outlier analysis, it might be difficult for the models to identify a hyperplane/separation \\\n",
    "    between class 3 and 1 with the rest of the class. Here we would like to explore if PCA's latent variables can show \\\n",
    "    a good separation between the \"weak anomalies\" from the rest. \n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Note the following: \n",
    "    <ol>\n",
    "        <li> Subset 1: Raw Data with Missing Data Deletion </li> \n",
    "        <li> Subset 2: Subset 1 + Outlier Removal </li> \n",
    "        <li> Subset 3: Subset 2 + Feature Transformation </li> \n",
    "        <li> Subset 4: Subset 3 + Feature Engineering  </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''<h3> PCA Analysis: </h3>'''))\n",
    "    for i, pca_df in enumerate(pca_list):\n",
    "        print(\"PCA plot for Subset {}:\".format(i))\n",
    "        display(analysis.pca_plot(pca_df))\n",
    "    \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> Subset 1: No clear separation between majority and minority class in PC1 and PC2. </li> \n",
    "        <li> Subset 2: Good separation of Class 2 from the rest in PC1 and PC2. </li> \n",
    "        <li> Subset 3: Acceptable separation of Class 4 from the rest in PC5 and PC6 </li> \n",
    "        <li> Subset 4: Same as Subset 3 </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: Use Subset 4 to create PC/latent variables.'''))\n",
    "\n",
    "with accordions[section_4].children[2]:\n",
    "    clear_output()\n",
    "    display(Markdown('''There are a total of 150 variables in the data. This section explores whether only some \\ \n",
    "    variables are relevant for the model training. There are 3 types of feature selection techniques i.e. filter,\\\n",
    "    wrapper and embedded, here we explore two methods from filter method i.e. ANOVA and Chi-square since the \\\n",
    "    target variable is categorical. ANOVA is used to explore numerical inputs while Chi-square is used to\\ \n",
    "    explore categorical inputs. Train Test Split is performed prior to feature selection to avoid leakage of \\\n",
    "    information.'''))\n",
    "    \n",
    "    display(Markdown('''<h3> Feature Selection: </h3>'''))\n",
    "    display(Markdown('''<h4> Feature Selection for Subset 1: </h4>'''))\n",
    "    X_train, X_test, y_train, y_test = train.traintest_split(combined_df1, test_size=0.3)\n",
    "    ANOVA_fs, chi2_fs = train.feature_selection(X_train, y_train, num_cols=\"all\")\n",
    "    display(train.feature_importance(ANOVA_fs, \"Feature importance with ANOVA for Subset 1\"))\n",
    "    display(train.feature_importance(chi2_fs, \"Feature importance with Chi2 for Subset 1\"))\n",
    "    \n",
    "    display(Markdown('''<h4> Feature Selection for Subset 4: </h4>'''))\n",
    "    X_train, X_test, y_train, y_test = train.traintest_split(combined_df4, test_size=0.3)\n",
    "    ANOVA_fs, chi2_fs = train.feature_selection(X_train, y_train, num_cols=\"all\")\n",
    "    display(train.feature_importance(ANOVA_fs, \"Feature importance with ANOVA for Subset 4\"))\n",
    "    display(train.feature_importance(chi2_fs, \"Feature importance with Chi2 for Subset 4\"))\n",
    "    \n",
    "    display(Markdown('''Observations: \\\n",
    "    <ol>\n",
    "        <li> There are 50 numerical variables that has p-value > 0.05. Will discard variables with p-value > 0.05. </li> \n",
    "        <li> All categorical variables has p-value < 0.05. </li> \n",
    "    </ol>\n",
    "    '''))\n",
    "    \n",
    "    display(Markdown('''Next Course of Action: \\\n",
    "    <ol>\n",
    "        <li> Numerical variables with p-value < 0.05 will be selected. </li> \n",
    "        <li> All categorical variables will be selected. </li> \n",
    "    </ol>\n",
    "    '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611e872d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T21:47:00.712354Z",
     "start_time": "2021-08-24T21:47:00.531349Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets.embed import embed_minimal_html\n",
    "embed_minimal_html('Technical_Assessment.html', views=[widget_fields], title='Multiclass_Classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7_multiclass",
   "language": "python",
   "name": "python3.7_multiclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
